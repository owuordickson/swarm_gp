Run-time: 3.929384469985962 seconds
Total allocated memory size: 215.0 KiB
Algorithm: ACO-GRAANK (v4.0)
No. of (dataset) attributes: 11
No. of (dataset) tuples: 589
Evaporation factor: 0.05
Minimum support: 0.5
Number of cores: 4
Number of patterns: 31
Number of iterations: 100

0. Age
1. ALB
2. ALP
3. ALT
4. AST
5. BIL
6. CHE
7. CHOL
8. CREA
9. GGT
10. PROT

File: ../data/hcv_data.csv

Pattern : Support
['2+', '6+'] : 0.541
['7+', '6+'] : 0.637
['6-', '9-'] : 0.565
['10-', '4-'] : 0.546
['3-', '7-'] : 0.568
['1-', '4-'] : 0.511
['6-', '4-'] : 0.545
['1-', '6-'] : 0.605
['9+', '3+'] : 0.64
['3-', '4-'] : 0.687
['1-', '10-'] : 0.684
['4+', '7-'] : 0.505
['9+', '10+'] : 0.55
['10-', '5-'] : 0.537
['2+', '8+'] : 0.51
['7+', '9+'] : 0.531
['2+', '4+'] : 0.52
['1-', '2+'] : 0.515
['3-', '10-'] : 0.561
['10-', '7-'] : 0.559
['7+', '0+'] : 0.547
['9+', '4+'] : 0.666
['9+', '8+'] : 0.549
['7+', '8+'] : 0.511
['1-', '7-'] : 0.541
['2+', '3+'] : 0.574
['10-', '8-'] : 0.536
['9+', '1+'] : 0.515
['2+', '9+'] : 0.552
['7+', '2+'] : 0.549
['3-', '6-'] : 0.625


Iterations 
Iteration: Best Cost
0: 0.0002090738030524775 
1: 0.0002090738030524775 
2: 0.0002090738030524775 
3: 0.0002090738030524775 
4: 0.0002090738030524775 
5: 0.0002090738030524775 
6: 0.0002090738030524775 
7: 0.0002090738030524775 
8: 0.0002090738030524775 
9: 0.0002090738030524775 
10: 0.0002090738030524775 
11: 0.0002090738030524775 
12: 0.0002090738030524775 
13: 0.0002090738030524775 
14: 0.0002090738030524775 
15: 0.0002090738030524775 
16: 0.0002090738030524775 
17: 0.0002090738030524775 
18: 0.0002090738030524775 
19: 0.0002090738030524775 
20: 0.0002090738030524775 
21: 0.0002090738030524775 
22: 0.0002090738030524775 
23: 0.0002090738030524775 
24: 0.0002090738030524775 
25: 0.0002090738030524775 
26: 0.0002090738030524775 
27: 0.0002090738030524775 
28: 0.0002090738030524775 
29: 0.0002090738030524775 
30: 0.0002090738030524775 
31: 0.0002090738030524775 
32: 0.0002090738030524775 
33: 0.0002090738030524775 
34: 0.0002090738030524775 
35: 0.0002090738030524775 
36: 0.0002090738030524775 
37: 0.0002090738030524775 
38: 0.0002090738030524775 
39: 0.0002090738030524775 
40: 0.0002090738030524775 
41: 0.0002090738030524775 
42: 0.0002090738030524775 
43: 0.0002090738030524775 
44: 0.0002090738030524775 
45: 0.0002090738030524775 
46: 0.0002090738030524775 
47: 0.0002090738030524775 
48: 0.0002090738030524775 
49: 0.0002090738030524775 
50: 0.0002090738030524775 
51: 0.0002090738030524775 
52: 0.0002090738030524775 
53: 0.0002090738030524775 
54: 0.0002090738030524775 
55: 0.0002090738030524775 
56: 0.0002090738030524775 
57: 0.0002090738030524775 
58: 0.0002090738030524775 
59: 0.0002090738030524775 
60: 0.0002090738030524775 
61: 0.0002090738030524775 
62: 0.0002090738030524775 
63: 0.0002090738030524775 
64: 0.0002090738030524775 
65: 0.0002090738030524775 
66: 0.0002090738030524775 
67: 0.0002090738030524775 
68: 0.0002090738030524775 
69: 0.0002090738030524775 
70: 0.0002090738030524775 
71: 0.0002090738030524775 
72: 0.0002090738030524775 
73: 0.0002090738030524775 
74: 0.0002090738030524775 
75: 0.0002090738030524775 
76: 0.0002090738030524775 
77: 0.0002090738030524775 
78: 0.0002090738030524775 
79: 0.0002090738030524775 
80: 0.0002090738030524775 
81: 0.0002090738030524775 
82: 0.0002090738030524775 
83: 0.0002090738030524775 
84: 0.0002090738030524775 
85: 0.0002090738030524775 
86: 0.0002090738030524775 
87: 0.0002090738030524775 
88: 0.0002090738030524775 
89: 0.0002090738030524775 
90: 0.0002090738030524775 
91: 0.0002090738030524775 
92: 0.0002090738030524775 
93: 0.0002090738030524775 
94: 0.0002090738030524775 
95: 0.0002090738030524775 
96: 0.0002090738030524775 
97: 0.0002090738030524775 
98: 0.0002090738030524775 
99: 0.0002090738030524775 
